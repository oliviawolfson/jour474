---
title: "Reverse Engineering Project"
author: "Student names here"
date: "Date here"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this notebook, we are reverse engineering the story, "As police struggle to solve homicides, Baltimore residents see an ‘open season for killing," written by Wesley Lowery, Steven Rich, and Salwan Georges. Link: <https://www.washingtonpost.com/investigations/as-police-struggle-to-solve-homicides-baltimore-residents-see-an-open-season-for-killing/2018/12/26/7ee561e4-fb24-11e8-8c9a-860ce2a8148f_story.html>

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
```

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data.

```{r}
# Load required data

# Path to data should be loaded from folder "data" i.e. read_csv("data/name_of_data.csv")

# Clean required data and prepare for analysis if needed. 
wbb_2022 <- read_csv("data/wbb_rosters_2022_23.csv") |> clean_names() 

wbb_2023 <-read_csv("data/wbb_rosters_2023_24.csv")|> clean_names() 

wbb_2021 <-read_csv("data/wbb_rosters_2021_22.csv")|> clean_names()

wbb_2020 <- read_csv("data/wbb_rosters_2020_21.csv")|> clean_names()

wbb_crosswalk <- read_csv("data/wbb_rosters23_crosswalk.csv") |> clean_names()


```

## Sentences to Engineer

In this notebook, we are reverse engineering five sentences from the story.

### Sentence 1

-   **Sentence text**:
-   **Analysis summary**: [Write up two to three sentences describing the results of your analysis. Were you able to confirm the finding? If not, why not?]
    -   {r}
        # Put code to reverse engineer sentence here


        # Display results of code below this codeblock

### Sentence 2

-   **Sentence text**:
-   **Analysis summary**:

```{r}
# Put code to reverse engineer sentence here
murder_data |>
 filter(str_detect(reported_date, "2015") | str_detect(reported_date, "2016") | str_detect(reported_date, "2017"))|>
  filter(str_detect(city, "Baltimore")) |>
  summarise(
    sum(str_detect(disposition, "Closed by arrest")) / n()  )

# Display results of code below this codeblock

```

### Sentence 3

-   **Sentence text**: In Chicago, the homicide arrest rate has dropped 21 percentage points, in Boston it has dropped 12 points and in St. Louis it is down 9.
-   **Analysis summary**: Chicago is 29.9% closed in 2014 and 8.5% in 2017 which gives Chicago a nearly 21% drop. St. Louis is 40.6% closed in 2014 and 31.6% closed in 2017 which gives St. Louis a 9% drop. Boston is 52% closed in 2014 and 40% closed in 2017 which gives Boston a 12% drop

```{r}
#St. Louis 
murder_data |>
  filter(str_detect(reported_date, "2014")) |>
  filter(str_detect(city, "St. Louis")) 

murder_data |>
  filter(str_detect(reported_date, "2014")) |>
  filter(str_detect(city, "St. Louis")) |>
    summarise(
  sum(str_detect(disposition, "Closed by arrest")) / n()
    )
murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "St. Louis")) 

murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "St. Louis")) |>
    summarise(
  sum(str_detect(disposition, "Closed by arrest")) / n()
    )

#Boston 
murder_data |>
  filter(str_detect(reported_date, "2014")) |>
  filter(str_detect(city, "Boston")) 

murder_data |>
  filter(str_detect(reported_date, "2014")) |>
  filter(str_detect(city, "Boston")) |>
    summarise(
  sum(str_detect(disposition, "Closed by arrest")) / n()
    )
murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Boston")) 

murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Boston")) |>
    summarise(
  sum(str_detect(disposition, "Closed by arrest")) / n()
    )

#Chicago 
murder_data |>
  filter(str_detect(reported_date, "2014")) |>
  filter(str_detect(city, "Chicago")) 

murder_data |>
  filter(str_detect(reported_date, "2014")) |>
  filter(str_detect(city, "Chicago")) |>
    summarise(
  sum(str_detect(disposition, "Closed by arrest")) / n()
    )
murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Chicago")) 

murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Chicago")) |>
    summarise(
  sum(str_detect(disposition, "Closed by arrest")) / n()
    )

```

### Sentence 4

-   **Sentence text**:

    Since 2015, the arrest rate hasn’t topped 30 percent in any year. (Baltimore)

-   **Analysis summary**:

    2017- 27.3% 2016 2016- 22.5% 2015- 25.4%

```{r}
murder_data |>
filter(str_detect(reported_date, "2015")) |>
  filter(str_detect(city, "Baltimore"))

murder_data |>
  filter(str_detect(reported_date, "2015")) |>
  filter(str_detect(city, "Baltimore")) |>
  summarize(
  sum(str_detect(disposition, "Closed by arrest")) / n())
    
murder_data |>
filter(str_detect(reported_date, "2016")) |>
  filter(str_detect(city, "Baltimore"))

murder_data |>
  filter(str_detect(reported_date, "2016")) |>
  filter(str_detect(city, "Baltimore")) |>
  summarize(
  sum(str_detect(disposition, "Closed by arrest")) / n())

murder_data |>
filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Baltimore"))

murder_data |>
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Baltimore")) |>
  summarize(
  sum(str_detect(disposition, "Closed by arrest")) / n())

murder_data |> 
  filter(str_detect(reported_date, "2017")) |>
  filter(str_detect(city, "Baltimore")) |>
  filter(str_detect(disposition, "Closed by arrest"))


```

### Sentence 5

-   **Sentence text**: In each of those neighborhoods, police make an arrest in fewer than 25 percent of cases, including 16 percent in Sandtown-Winchester."
-   **Analysis summary**: In order to find the percentages in a certain town, first research was done about the exact coordinates of Sandtown-Winchester. Then we imputed these numbers into Str_detect and found how many of these were closed with an arrest. In order to find the zip code of Sandtown-Winchester, we did a google search on the longitude and latitude of the town. The issue with route, is that it's an approximation and theoretically could be wrong because it's not exact. (We were unsure if the range was fully accurate). In order to find specific longitude and latitude we would use “TidyGeocoder,” but we did not have the capacity to run this full code because it would take a great length of time.

```{r}
murder_data |>
filter(str_detect(lat,'39.303')) |>
filter(str_detect(lon,'-76.64')) |>
  summarize(
  sum(str_detect(disposition, "Closed by arrest")) / n())


```

-30-
